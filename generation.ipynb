{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTuM__nfeaIo",
    "outputId": "e1b52188-460b-493c-b63d-1dbeef96c9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CB-LLMs'...\n",
      "remote: Enumerating objects: 100, done.\u001b[K\n",
      "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
      "remote: Total 100 (delta 41), reused 56 (delta 19), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (100/100), 921.58 KiB | 5.18 MiB/s, done.\n",
      "Resolving deltas: 100% (41/41), done.\n",
      "/home/mac043/teams/dsmlp/Text Generation/CB-LLMs\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/Trustworthy-ML-Lab/CB-LLMs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t54kx34neuc5"
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8EGexqLgQTL"
   },
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "C1DGU0JEeuIc",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "571d2c5c-0684-46e5-dce2-a21a9c1cb580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mac043/teams/dsmlp/Concept-Bottleneck-LLM/generation\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==2.4.0 in /home/mac043/.local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: transformers==4.44.0 in /home/mac043/.local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.44.0)\n",
      "Requirement already satisfied: datasets==3.0.2 in /home/mac043/.local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: peft==0.13.2 in /home/mac043/.local/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: evaluate==0.4.3 in /home/mac043/.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mac043/.local/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/mac043/.local/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/mac043/.local/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/mac043/.local/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.0.2->-r requirements.txt (line 3)) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.0.2->-r requirements.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==3.0.2->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==3.0.2->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets==3.0.2->-r requirements.txt (line 3)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==3.0.2->-r requirements.txt (line 3)) (3.9.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.13.2->-r requirements.txt (line 4)) (5.9.8)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.13.2->-r requirements.txt (line 4)) (0.34.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.0.2->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.0.2->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.0.2->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.0.2->-r requirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.0.2->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.4.0->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.0.2->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.0.2->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.0.2->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision==0.19.0 in /home/mac043/.local/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision==0.19.0) (1.26.4)\n",
      "Requirement already satisfied: torch==2.4.0 in /home/mac043/.local/lib/python3.11/site-packages (from torchvision==0.19.0) (2.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision==0.19.0) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mac043/.local/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/mac043/.local/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/mac043/.local/lib/python3.11/site-packages (from torch==2.4.0->torchvision==0.19.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision==0.19.0) (12.1.105)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.4.0->torchvision==0.19.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.4.0->torchvision==0.19.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 61.5 ms, sys: 30.9 ms, total: 92.4 ms\n",
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%cd generation\n",
    "%pip install -r requirements.txt\n",
    "%pip install torchvision==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "x-FWtKB6gGbb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6a343f70-42ee-4e53-9f97-dc20412fedee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "Cloning into 'temp_repo'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
      "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
      "remote: Total 37 (delta 8), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (37/37), 8.02 KiB | 820.00 KiB/s, done.\n",
      "Filtering content: 100% (8/8), 1.68 GiB | 38.05 MiB/s, done.\n",
      "CPU times: user 255 ms, sys: 44.4 ms, total: 299 ms\n",
      "Wall time: 47.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Download finetuned CB-LLMs\n",
    "!git lfs install\n",
    "!git clone https://huggingface.co/cesun/cbllm-generation temp_repo\n",
    "!mv temp_repo/from_pretained_llama3_lora_cbm .\n",
    "!rm -rf temp_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFSIeLHivDCB",
    "outputId": "8e34aebc-4399-41a8-a1e3-9c3c04138085"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb152e5f84634f559d9b840b51bb14f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarcusChang\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "# !huggingface-cli login\n",
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyL83Q2HgXKg"
   },
   "source": [
    "### 2. Training\n",
    "Models:\n",
    "- `meta-llama/Llama-3.2-3B-Instruct`: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear CUDA memory to avoid OOM errors\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oSZ9nAyQgNtj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mac043/.local/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "loading data...\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "training data len:  6920\n",
      "val data len:  872\n",
      "tokenizing...\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py\", line 406, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mac043/.local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 402, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1232, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1339, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1854, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1746, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1666, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 364, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 388, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py\", line 423, in hf_raise_for_status\n",
      "    raise _format(GatedRepoError, message, response) from e\n",
      "huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-6834eabe-2e9e40061ff4254546451766;eb729f45-9e35-4b0a-b6d2-7a31a22460f4)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Llama-3.2-3B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mac043/teams/dsmlp/Concept-Bottleneck-LLM/generation/train_CBLLM.py\", line 67, in <module>\n",
      "    config = LlamaConfig.from_pretrained(args.model_id)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mac043/.local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 603, in from_pretrained\n",
      "    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mac043/.local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 632, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mac043/.local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/home/mac043/.local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 420, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct.\n",
      "401 Client Error. (Request ID: Root=1-6834eabe-2e9e40061ff4254546451766;eb729f45-9e35-4b0a-b6d2-7a31a22460f4)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Llama-3.2-3B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "CPU times: user 145 ms, sys: 40.9 ms, total: 186 ms\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train a CB-LLM\n",
    "!python train_CBLLM.py \\\n",
    "    --dataset 'SetFit/sst2' \\\n",
    "    --model_id 'meta-llama/Llama-3.2-3B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record peak memory usage\n",
    "peak_memory = torch.cuda.max_memory_allocated() / 1024**2  # MB\n",
    "print(f\"Peak allocated memory: {peak_memory:.2f} MB\")\n",
    "\n",
    "peak_reserved = torch.cuda.max_memory_reserved() / 1024**2  # MB\n",
    "print(f\"Peak reserved memory: {peak_reserved:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNsQLzb9gzIn"
   },
   "source": [
    "### 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUPUMPPMg1ND",
    "outputId": "4e3c3078-ca05-4384-f8ba-65be09065f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-13 22:34:58.909933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747175698.929656    7966 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747175698.935695    7966 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-13 22:34:58.956044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "loading data...\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n",
      "test data len:  1821\n",
      "tokenizing...\n",
      "config.json: 100% 654/654 [00:00<00:00, 4.26MB/s]\n",
      "tokenizer_config.json: 100% 50.6k/50.6k [00:00<00:00, 40.7MB/s]\n",
      "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 10.3MB/s]\n",
      "special_tokens_map.json: 100% 73.0/73.0 [00:00<00:00, 488kB/s]\n",
      "Map: 100% 1821/1821 [00:00<00:00, 8879.40 examples/s]\n",
      "concept len:  2\n",
      "creating loader...\n",
      "preparing backbone\n",
      "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 85.8MB/s]\n",
      "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
      "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1% 41.9M/4.98G [00:00<00:12, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2% 94.4M/4.98G [00:00<00:10, 469MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   3% 147M/4.98G [00:00<00:12, 400MB/s] \u001b[A\n",
      "model-00001-of-00004.safetensors:   4% 189M/4.98G [00:00<00:12, 386MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5% 231M/4.98G [00:00<00:12, 389MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5% 273M/4.98G [00:00<00:12, 387MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6% 315M/4.98G [00:00<00:12, 385MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   7% 357M/4.98G [00:00<00:12, 369MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   8% 398M/4.98G [00:01<00:12, 375MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   9% 440M/4.98G [00:01<00:15, 291MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10% 482M/4.98G [00:01<00:15, 285MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10% 514M/4.98G [00:01<00:20, 218MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11% 545M/4.98G [00:01<00:24, 183MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  12% 577M/4.98G [00:02<00:27, 159MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  12% 608M/4.98G [00:02<00:24, 182MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13% 650M/4.98G [00:02<00:19, 222MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14% 692M/4.98G [00:02<00:17, 251MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  15% 734M/4.98G [00:02<00:15, 279MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  15% 765M/4.98G [00:02<00:14, 285MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  16% 797M/4.98G [00:02<00:14, 291MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17% 828M/4.98G [00:02<00:14, 290MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17% 870M/4.98G [00:03<00:13, 301MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  18% 912M/4.98G [00:03<00:12, 318MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  19% 954M/4.98G [00:03<00:12, 312MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  20% 996M/4.98G [00:03<00:13, 290MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21% 1.03G/4.98G [00:03<00:14, 277MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21% 1.06G/4.98G [00:03<00:14, 271MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  22% 1.09G/4.98G [00:03<00:15, 255MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  23% 1.12G/4.98G [00:04<00:15, 245MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  23% 1.16G/4.98G [00:04<00:14, 268MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  24% 1.20G/4.98G [00:04<00:14, 264MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25% 1.23G/4.98G [00:04<00:14, 258MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25% 1.26G/4.98G [00:04<00:15, 247MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  26% 1.29G/4.98G [00:04<00:15, 237MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  27% 1.32G/4.98G [00:04<00:15, 237MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  27% 1.36G/4.98G [00:04<00:13, 259MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  28% 1.39G/4.98G [00:05<00:13, 261MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29% 1.43G/4.98G [00:05<00:13, 259MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29% 1.46G/4.98G [00:05<00:16, 214MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30% 1.50G/4.98G [00:05<00:13, 252MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31% 1.53G/4.98G [00:05<00:13, 251MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31% 1.56G/4.98G [00:05<00:12, 263MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  32% 1.59G/4.98G [00:05<00:13, 260MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  33% 1.63G/4.98G [00:06<00:13, 257MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  33% 1.66G/4.98G [00:06<00:12, 257MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  34% 1.69G/4.98G [00:06<00:14, 235MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  35% 1.72G/4.98G [00:06<00:13, 234MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  35% 1.75G/4.98G [00:06<00:13, 232MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36% 1.78G/4.98G [00:06<00:13, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36% 1.81G/4.98G [00:06<00:12, 253MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  37% 1.86G/4.98G [00:06<00:12, 250MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  38% 1.89G/4.98G [00:08<00:41, 74.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  39% 1.92G/4.98G [00:08<00:32, 93.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  39% 1.96G/4.98G [00:08<00:23, 128MB/s] \u001b[A\n",
      "model-00001-of-00004.safetensors:  40% 2.00G/4.98G [00:08<00:17, 166MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  41% 2.04G/4.98G [00:08<00:14, 203MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  42% 2.09G/4.98G [00:08<00:12, 237MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  43% 2.13G/4.98G [00:08<00:10, 268MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  44% 2.17G/4.98G [00:08<00:09, 295MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  44% 2.21G/4.98G [00:09<00:08, 309MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  45% 2.25G/4.98G [00:09<00:08, 314MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  46% 2.30G/4.98G [00:09<00:08, 301MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47% 2.34G/4.98G [00:09<00:09, 285MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48% 2.37G/4.98G [00:09<00:09, 287MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48% 2.40G/4.98G [00:09<00:09, 272MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  49% 2.43G/4.98G [00:09<00:09, 270MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50% 2.46G/4.98G [00:09<00:09, 264MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50% 2.50G/4.98G [00:10<00:13, 181MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51% 2.54G/4.98G [00:10<00:11, 219MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52% 2.58G/4.98G [00:10<00:09, 245MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  53% 2.62G/4.98G [00:10<00:08, 271MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  54% 2.66G/4.98G [00:12<00:43, 53.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  55% 2.72G/4.98G [00:12<00:28, 79.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  56% 2.77G/4.98G [00:13<00:20, 110MB/s] \u001b[A\n",
      "model-00001-of-00004.safetensors:  56% 2.81G/4.98G [00:13<00:16, 135MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  57% 2.85G/4.98G [00:13<00:13, 163MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  58% 2.89G/4.98G [00:13<00:10, 191MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  59% 2.94G/4.98G [00:14<00:17, 117MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  60% 2.99G/4.98G [00:14<00:12, 157MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  61% 3.03G/4.98G [00:14<00:10, 190MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  62% 3.07G/4.98G [00:14<00:08, 214MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  63% 3.11G/4.98G [00:14<00:08, 232MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  63% 3.16G/4.98G [00:16<00:35, 51.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  64% 3.19G/4.98G [00:17<00:28, 62.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  65% 3.23G/4.98G [00:17<00:20, 83.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  66% 3.26G/4.98G [00:17<00:16, 102MB/s] \u001b[A\n",
      "model-00001-of-00004.safetensors:  66% 3.29G/4.98G [00:17<00:13, 124MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  67% 3.33G/4.98G [00:17<00:10, 159MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68% 3.37G/4.98G [00:17<00:08, 181MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68% 3.41G/4.98G [00:17<00:07, 214MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  69% 3.44G/4.98G [00:17<00:06, 224MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70% 3.47G/4.98G [00:18<00:06, 235MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70% 3.50G/4.98G [00:18<00:06, 229MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71% 3.53G/4.98G [00:18<00:06, 238MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72% 3.57G/4.98G [00:18<00:05, 244MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72% 3.60G/4.98G [00:18<00:05, 251MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73% 3.63G/4.98G [00:18<00:05, 256MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74% 3.66G/4.98G [00:18<00:05, 257MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74% 3.69G/4.98G [00:18<00:04, 268MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75% 3.72G/4.98G [00:20<00:28, 44.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76% 3.77G/4.98G [00:21<00:16, 70.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  77% 3.83G/4.98G [00:21<00:11, 104MB/s] \u001b[A\n",
      "model-00001-of-00004.safetensors:  78% 3.87G/4.98G [00:21<00:08, 132MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79% 3.91G/4.98G [00:21<00:06, 157MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79% 3.95G/4.98G [00:21<00:05, 187MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  80% 4.00G/4.98G [00:21<00:04, 202MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  81% 4.03G/4.98G [00:21<00:04, 220MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82% 4.06G/4.98G [00:21<00:03, 233MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82% 4.09G/4.98G [00:22<00:03, 238MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83% 4.12G/4.98G [00:22<00:03, 236MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83% 4.15G/4.98G [00:22<00:03, 243MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84% 4.18G/4.98G [00:22<00:03, 247MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  85% 4.22G/4.98G [00:22<00:03, 250MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  85% 4.25G/4.98G [00:22<00:02, 249MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  86% 4.28G/4.98G [00:22<00:02, 235MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87% 4.31G/4.98G [00:23<00:03, 195MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87% 4.34G/4.98G [00:23<00:03, 170MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88% 4.36G/4.98G [00:23<00:03, 174MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88% 4.40G/4.98G [00:23<00:02, 218MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90% 4.46G/4.98G [00:23<00:02, 248MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90% 4.49G/4.98G [00:23<00:02, 214MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  91% 4.54G/4.98G [00:24<00:01, 265MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92% 4.57G/4.98G [00:24<00:01, 217MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92% 4.60G/4.98G [00:24<00:01, 229MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93% 4.65G/4.98G [00:24<00:01, 269MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  94% 4.68G/4.98G [00:24<00:01, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95% 4.72G/4.98G [00:24<00:01, 245MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  96% 4.76G/4.98G [00:24<00:00, 276MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  96% 4.79G/4.98G [00:25<00:00, 239MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  97% 4.82G/4.98G [00:25<00:00, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98% 4.87G/4.98G [00:25<00:00, 279MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98% 4.90G/4.98G [00:25<00:00, 241MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  99% 4.93G/4.98G [00:25<00:00, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:25<00:00, 193MB/s]\n",
      "Downloading shards:  25% 1/4 [00:26<01:18, 26.08s/it]\n",
      "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1% 52.4M/5.00G [00:00<00:11, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2% 105M/5.00G [00:00<00:12, 402MB/s] \u001b[A\n",
      "model-00002-of-00004.safetensors:   3% 147M/5.00G [00:00<00:12, 402MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4% 199M/5.00G [00:00<00:12, 376MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5% 241M/5.00G [00:00<00:16, 280MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5% 273M/5.00G [00:00<00:18, 259MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6% 304M/5.00G [00:01<00:23, 196MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7% 357M/5.00G [00:01<00:18, 252MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   8% 398M/5.00G [00:01<00:16, 277MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9% 440M/5.00G [00:01<00:16, 279MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9% 472M/5.00G [00:01<00:18, 248MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  10% 503M/5.00G [00:01<00:24, 187MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  11% 535M/5.00G [00:07<03:39, 20.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12% 587M/5.00G [00:07<02:15, 32.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  13% 640M/5.00G [00:07<01:28, 49.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14% 682M/5.00G [00:07<01:06, 65.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14% 724M/5.00G [00:07<00:55, 77.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15% 755M/5.00G [00:11<02:33, 27.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  16% 807M/5.00G [00:11<01:39, 42.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17% 849M/5.00G [00:11<01:12, 56.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  18% 891M/5.00G [00:11<00:59, 68.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  19% 933M/5.00G [00:11<00:45, 90.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  20% 975M/5.00G [00:12<00:34, 116MB/s] \u001b[A\n",
      "model-00002-of-00004.safetensors:  20% 1.01G/5.00G [00:12<00:30, 130MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21% 1.04G/5.00G [00:12<00:27, 145MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21% 1.07G/5.00G [00:12<00:24, 164MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  22% 1.10G/5.00G [00:12<00:21, 179MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  23% 1.13G/5.00G [00:12<00:19, 203MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  23% 1.16G/5.00G [00:12<00:18, 205MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  24% 1.20G/5.00G [00:13<00:17, 218MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  25% 1.23G/5.00G [00:13<00:15, 238MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  25% 1.26G/5.00G [00:13<00:17, 214MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  26% 1.29G/5.00G [00:13<00:16, 229MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27% 1.33G/5.00G [00:13<00:13, 267MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27% 1.36G/5.00G [00:13<00:14, 257MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28% 1.39G/5.00G [00:13<00:14, 243MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29% 1.44G/5.00G [00:13<00:13, 269MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29% 1.47G/5.00G [00:14<00:14, 251MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  30% 1.50G/5.00G [00:14<00:13, 250MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  31% 1.53G/5.00G [00:14<00:13, 255MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  31% 1.56G/5.00G [00:14<00:13, 249MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  32% 1.59G/5.00G [00:14<00:13, 246MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  33% 1.63G/5.00G [00:14<00:13, 253MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  33% 1.66G/5.00G [00:14<00:13, 245MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  34% 1.69G/5.00G [00:14<00:12, 262MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  34% 1.72G/5.00G [00:15<00:13, 252MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  35% 1.75G/5.00G [00:15<00:13, 242MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  36% 1.79G/5.00G [00:15<00:12, 249MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  36% 1.82G/5.00G [00:15<00:12, 261MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  37% 1.86G/5.00G [00:15<00:13, 238MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  38% 1.89G/5.00G [00:15<00:12, 252MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  38% 1.92G/5.00G [00:15<00:11, 264MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39% 1.96G/5.00G [00:15<00:10, 291MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  40% 1.99G/5.00G [00:16<00:14, 207MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  40% 2.02G/5.00G [00:16<00:15, 196MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  41% 2.06G/5.00G [00:16<00:14, 204MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  42% 2.09G/5.00G [00:16<00:13, 219MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  43% 2.13G/5.00G [00:16<00:11, 241MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  43% 2.16G/5.00G [00:16<00:11, 243MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  44% 2.19G/5.00G [00:17<00:11, 252MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  45% 2.23G/5.00G [00:17<00:10, 269MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  45% 2.26G/5.00G [00:17<00:10, 263MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  46% 2.30G/5.00G [00:17<00:10, 261MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47% 2.33G/5.00G [00:17<00:10, 261MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47% 2.36G/5.00G [00:17<00:09, 274MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  48% 2.40G/5.00G [00:17<00:08, 295MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49% 2.43G/5.00G [00:17<00:09, 285MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49% 2.46G/5.00G [00:18<00:08, 282MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  50% 2.50G/5.00G [00:18<00:10, 230MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51% 2.53G/5.00G [00:18<00:19, 126MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51% 2.55G/5.00G [00:25<03:15, 12.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  52% 2.60G/5.00G [00:29<03:05, 13.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  53% 2.63G/5.00G [00:29<02:15, 17.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  53% 2.65G/5.00G [00:29<01:48, 21.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  54% 2.71G/5.00G [00:30<01:03, 36.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  55% 2.75G/5.00G [00:30<00:43, 51.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56% 2.78G/5.00G [00:30<00:34, 65.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56% 2.82G/5.00G [00:30<00:24, 89.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  57% 2.86G/5.00G [00:30<00:18, 116MB/s] \u001b[A\n",
      "model-00002-of-00004.safetensors:  58% 2.90G/5.00G [00:30<00:15, 139MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  59% 2.94G/5.00G [00:30<00:13, 153MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  59% 2.97G/5.00G [00:30<00:11, 172MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  60% 3.01G/5.00G [00:31<00:09, 203MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  61% 3.04G/5.00G [00:31<00:09, 206MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  61% 3.07G/5.00G [00:31<00:09, 206MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  62% 3.10G/5.00G [00:31<00:08, 218MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63% 3.14G/5.00G [00:31<00:07, 238MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63% 3.17G/5.00G [00:31<00:07, 247MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  64% 3.20G/5.00G [00:31<00:08, 215MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  65% 3.23G/5.00G [00:32<00:07, 232MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  65% 3.27G/5.00G [00:32<00:06, 271MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  66% 3.30G/5.00G [00:32<00:06, 251MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  67% 3.34G/5.00G [00:32<00:06, 250MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  68% 3.38G/5.00G [00:32<00:06, 236MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  68% 3.42G/5.00G [00:32<00:05, 272MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  69% 3.45G/5.00G [00:32<00:06, 257MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70% 3.48G/5.00G [00:32<00:05, 263MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70% 3.51G/5.00G [00:33<00:06, 245MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  71% 3.54G/5.00G [00:33<00:07, 208MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  72% 3.58G/5.00G [00:33<00:06, 228MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  72% 3.61G/5.00G [00:33<00:06, 226MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  73% 3.65G/5.00G [00:33<00:05, 256MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  74% 3.69G/5.00G [00:33<00:04, 289MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  75% 3.73G/5.00G [00:33<00:04, 296MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  75% 3.76G/5.00G [00:34<00:05, 227MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  76% 3.81G/5.00G [00:34<00:04, 264MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  77% 3.86G/5.00G [00:34<00:04, 265MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  78% 3.89G/5.00G [00:34<00:04, 243MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79% 3.93G/5.00G [00:34<00:03, 279MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79% 3.96G/5.00G [00:34<00:03, 278MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  80% 4.00G/5.00G [00:35<00:04, 236MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  81% 4.03G/5.00G [00:35<00:03, 246MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  82% 4.08G/5.00G [00:35<00:03, 296MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  82% 4.11G/5.00G [00:35<00:03, 237MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  83% 4.14G/5.00G [00:35<00:04, 193MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  83% 4.17G/5.00G [00:35<00:04, 188MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  84% 4.22G/5.00G [00:36<00:03, 220MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  85% 4.25G/5.00G [00:36<00:03, 237MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  86% 4.28G/5.00G [00:36<00:02, 248MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  86% 4.32G/5.00G [00:36<00:02, 281MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  87% 4.35G/5.00G [00:36<00:02, 273MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88% 4.38G/5.00G [00:36<00:02, 265MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88% 4.41G/5.00G [00:36<00:02, 265MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  89% 4.45G/5.00G [00:36<00:02, 251MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90% 4.48G/5.00G [00:37<00:01, 265MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90% 4.51G/5.00G [00:37<00:01, 252MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91% 4.54G/5.00G [00:37<00:01, 259MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91% 4.57G/5.00G [00:37<00:01, 223MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  92% 4.60G/5.00G [00:37<00:02, 138MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  92% 4.62G/5.00G [00:41<00:18, 20.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  93% 4.67G/5.00G [00:42<00:10, 32.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  94% 4.71G/5.00G [00:42<00:06, 47.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  95% 4.74G/5.00G [00:42<00:04, 61.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  95% 4.77G/5.00G [00:42<00:02, 76.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  96% 4.80G/5.00G [00:42<00:02, 96.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  97% 4.83G/5.00G [00:42<00:01, 116MB/s] \u001b[A\n",
      "model-00002-of-00004.safetensors:  97% 4.87G/5.00G [00:42<00:00, 135MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  98% 4.90G/5.00G [00:43<00:00, 152MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  99% 4.93G/5.00G [00:43<00:00, 172MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  99% 4.96G/5.00G [00:43<00:00, 196MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:46<00:00, 108MB/s]\n",
      "Downloading shards:  50% 2/4 [01:12<01:16, 38.14s/it]\n",
      "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   1% 52.4M/4.92G [00:00<00:10, 453MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   2% 105M/4.92G [00:00<00:10, 461MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:   3% 157M/4.92G [00:00<00:12, 389MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   4% 199M/4.92G [00:00<00:13, 350MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   5% 241M/4.92G [00:00<00:13, 344MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   6% 283M/4.92G [00:00<00:14, 325MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7% 325M/4.92G [00:00<00:15, 288MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7% 357M/4.92G [00:01<00:17, 266MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   8% 388M/4.92G [00:01<00:17, 258MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   9% 419M/4.92G [00:01<00:18, 239MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   9% 451M/4.92G [00:02<00:38, 116MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  10% 472M/4.92G [00:05<03:14, 22.8MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  10% 514M/4.92G [00:05<02:04, 35.4MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  11% 556M/4.92G [00:05<01:23, 51.9MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  12% 587M/4.92G [00:06<01:04, 67.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  13% 619M/4.92G [00:06<00:51, 84.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  13% 650M/4.92G [00:06<00:41, 103MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  14% 682M/4.92G [00:06<00:34, 123MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15% 713M/4.92G [00:06<00:28, 148MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15% 755M/4.92G [00:06<00:22, 189MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  16% 797M/4.92G [00:06<00:18, 219MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  17% 828M/4.92G [00:07<00:24, 169MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  17% 860M/4.92G [00:11<03:05, 21.8MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  19% 912M/4.92G [00:11<01:54, 35.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20% 965M/4.92G [00:12<01:15, 52.3MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20% 1.01G/4.92G [00:12<00:56, 69.5MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  21% 1.05G/4.92G [00:12<00:42, 90.6MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  22% 1.09G/4.92G [00:12<00:33, 113MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  23% 1.13G/4.92G [00:12<00:26, 143MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  24% 1.17G/4.92G [00:12<00:23, 159MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  25% 1.21G/4.92G [00:12<00:21, 172MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  25% 1.24G/4.92G [00:13<00:22, 164MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  26% 1.27G/4.92G [00:13<00:21, 173MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  26% 1.30G/4.92G [00:18<02:47, 21.6MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  27% 1.32G/4.92G [00:18<02:15, 26.5MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  28% 1.36G/4.92G [00:18<01:27, 40.5MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  29% 1.41G/4.92G [00:18<00:59, 58.7MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  29% 1.44G/4.92G [00:18<00:46, 74.8MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  30% 1.47G/4.92G [00:18<00:37, 93.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  31% 1.51G/4.92G [00:18<00:27, 124MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  32% 1.55G/4.92G [00:18<00:21, 157MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  32% 1.58G/4.92G [00:19<00:18, 179MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33% 1.61G/4.92G [00:19<00:17, 187MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33% 1.65G/4.92G [00:19<00:15, 205MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  34% 1.68G/4.92G [00:19<00:15, 213MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  35% 1.71G/4.92G [00:19<00:14, 223MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  35% 1.74G/4.92G [00:19<00:20, 153MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  36% 1.76G/4.92G [00:20<00:32, 98.2MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  36% 1.78G/4.92G [00:24<02:44, 19.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  37% 1.84G/4.92G [00:24<01:30, 34.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  38% 1.89G/4.92G [00:24<00:56, 53.8MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  39% 1.92G/4.92G [00:24<00:43, 68.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  40% 1.95G/4.92G [00:24<00:34, 85.8MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  40% 1.98G/4.92G [00:24<00:29, 101MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  41% 2.01G/4.92G [00:25<00:29, 99.5MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  42% 2.04G/4.92G [00:28<01:39, 28.9MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  42% 2.08G/4.92G [00:28<01:13, 38.7MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  43% 2.11G/4.92G [00:28<00:53, 52.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  44% 2.15G/4.92G [00:28<00:37, 74.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  44% 2.18G/4.92G [00:28<00:30, 90.6MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  45% 2.21G/4.92G [00:28<00:24, 109MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  46% 2.24G/4.92G [00:29<00:20, 131MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  46% 2.28G/4.92G [00:29<00:16, 157MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  47% 2.31G/4.92G [00:29<00:14, 183MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  48% 2.34G/4.92G [00:29<00:12, 202MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  48% 2.38G/4.92G [00:29<00:11, 223MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  49% 2.41G/4.92G [00:29<00:10, 235MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  50% 2.44G/4.92G [00:29<00:10, 231MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  50% 2.47G/4.92G [00:29<00:10, 232MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  51% 2.51G/4.92G [00:30<00:10, 238MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  52% 2.55G/4.92G [00:30<00:09, 252MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  52% 2.58G/4.92G [00:30<00:08, 266MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  53% 2.61G/4.92G [00:30<00:08, 275MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  54% 2.64G/4.92G [00:30<00:08, 255MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  54% 2.67G/4.92G [00:30<00:08, 257MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  55% 2.71G/4.92G [00:30<00:08, 268MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  56% 2.74G/4.92G [00:30<00:08, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  56% 2.77G/4.92G [00:31<00:08, 248MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  57% 2.80G/4.92G [00:31<00:08, 259MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  58% 2.83G/4.92G [00:31<00:08, 254MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  58% 2.86G/4.92G [00:31<00:07, 259MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  59% 2.89G/4.92G [00:31<00:07, 255MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  60% 2.93G/4.92G [00:31<00:07, 256MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  60% 2.96G/4.92G [00:31<00:07, 256MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  61% 2.99G/4.92G [00:34<00:52, 37.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  62% 3.03G/4.92G [00:34<00:34, 55.2MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  62% 3.06G/4.92G [00:34<00:26, 71.2MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  63% 3.10G/4.92G [00:34<00:18, 98.2MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  64% 3.15G/4.92G [00:34<00:14, 124MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  65% 3.18G/4.92G [00:34<00:12, 138MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  65% 3.21G/4.92G [00:35<00:10, 158MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  66% 3.25G/4.92G [00:35<00:08, 187MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  67% 3.28G/4.92G [00:35<00:08, 198MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  67% 3.31G/4.92G [00:35<00:07, 210MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  68% 3.34G/4.92G [00:35<00:07, 212MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  69% 3.38G/4.92G [00:35<00:06, 233MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  69% 3.41G/4.92G [00:35<00:06, 239MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  70% 3.44G/4.92G [00:35<00:06, 240MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  71% 3.47G/4.92G [00:36<00:05, 245MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  71% 3.50G/4.92G [00:36<00:05, 249MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  72% 3.53G/4.92G [00:36<00:05, 256MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  73% 3.57G/4.92G [00:36<00:08, 165MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  73% 3.60G/4.92G [00:36<00:08, 147MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  74% 3.62G/4.92G [00:37<00:08, 145MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  74% 3.65G/4.92G [00:37<00:07, 169MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  75% 3.69G/4.92G [00:37<00:05, 212MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  76% 3.73G/4.92G [00:37<00:04, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  77% 3.77G/4.92G [00:37<00:03, 288MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  78% 3.82G/4.92G [00:37<00:04, 221MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  78% 3.85G/4.92G [00:38<00:05, 188MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  79% 3.88G/4.92G [00:38<00:05, 190MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  80% 3.91G/4.92G [00:38<00:04, 211MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  80% 3.94G/4.92G [00:38<00:04, 216MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  81% 3.97G/4.92G [00:38<00:04, 214MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  82% 4.02G/4.92G [00:38<00:03, 250MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  83% 4.06G/4.92G [00:38<00:03, 264MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  83% 4.09G/4.92G [00:42<00:28, 28.6MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  84% 4.11G/4.92G [00:42<00:24, 33.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  84% 4.13G/4.92G [00:43<00:19, 39.6MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  84% 4.15G/4.92G [00:43<00:15, 48.7MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  85% 4.18G/4.92G [00:43<00:10, 68.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  86% 4.22G/4.92G [00:43<00:07, 90.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  86% 4.25G/4.92G [00:43<00:05, 115MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  87% 4.28G/4.92G [00:43<00:04, 142MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  88% 4.32G/4.92G [00:43<00:03, 183MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  89% 4.36G/4.92G [00:43<00:02, 225MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  90% 4.41G/4.92G [00:44<00:01, 279MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  91% 4.46G/4.92G [00:44<00:02, 218MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  91% 4.49G/4.92G [00:44<00:02, 197MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  92% 4.54G/4.92G [00:44<00:01, 215MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  93% 4.57G/4.92G [00:50<00:17, 20.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  93% 4.59G/4.92G [00:50<00:13, 24.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  94% 4.63G/4.92G [00:51<00:07, 35.7MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  95% 4.68G/4.92G [00:51<00:04, 51.0MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  96% 4.71G/4.92G [00:51<00:03, 65.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  96% 4.74G/4.92G [00:51<00:02, 82.7MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  97% 4.78G/4.92G [00:51<00:01, 111MB/s] \u001b[A\n",
      "model-00003-of-00004.safetensors:  98% 4.82G/4.92G [00:51<00:00, 146MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  99% 4.87G/4.92G [00:51<00:00, 161MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:52<00:00, 94.5MB/s]\n",
      "Downloading shards:  75% 3/4 [02:04<00:44, 44.59s/it]\n",
      "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   4% 41.9M/1.17G [00:00<00:02, 378MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   7% 83.9M/1.17G [00:04<01:12, 14.9MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  12% 136M/1.17G [00:04<00:34, 29.7MB/s] \u001b[A\n",
      "model-00004-of-00004.safetensors:  16% 189M/1.17G [00:05<00:19, 49.2MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  20% 231M/1.17G [00:05<00:13, 68.8MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  23% 273M/1.17G [00:05<00:09, 90.7MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  27% 315M/1.17G [00:05<00:07, 115MB/s] \u001b[A\n",
      "model-00004-of-00004.safetensors:  31% 357M/1.17G [00:05<00:05, 144MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  34% 398M/1.17G [00:05<00:04, 172MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  38% 440M/1.17G [00:05<00:03, 182MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  41% 482M/1.17G [00:06<00:03, 211MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  45% 524M/1.17G [00:06<00:02, 221MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  48% 556M/1.17G [00:06<00:02, 215MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  50% 587M/1.17G [00:06<00:02, 221MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  53% 619M/1.17G [00:06<00:02, 226MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  56% 650M/1.17G [00:06<00:02, 229MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  58% 682M/1.17G [00:06<00:01, 244MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  61% 713M/1.17G [00:06<00:01, 243MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  65% 755M/1.17G [00:07<00:01, 258MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  67% 786M/1.17G [00:07<00:01, 246MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  71% 828M/1.17G [00:07<00:01, 285MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  74% 860M/1.17G [00:07<00:01, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  77% 902M/1.17G [00:07<00:01, 263MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  80% 933M/1.17G [00:07<00:00, 264MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  83% 965M/1.17G [00:07<00:00, 234MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  86% 1.01G/1.17G [00:08<00:00, 272MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  89% 1.04G/1.17G [00:08<00:00, 228MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  92% 1.08G/1.17G [00:08<00:00, 258MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  96% 1.12G/1.17G [00:08<00:00, 273MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:08<00:00, 133MB/s]\n",
      "Downloading shards: 100% 4/4 [02:13<00:00, 33.50s/it]\n",
      "Loading checkpoint shards: 100% 4/4 [00:02<00:00,  1.58it/s]\n",
      "/content/CB-LLMs/generation/test_concepts.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cbl.load_state_dict(torch.load(cbl_path, map_location=device))\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/CB-LLMs/generation/test_concepts.py\", line 86, in <module>\n",
      "    cbl.load_state_dict(torch.load(cbl_path, map_location=device))\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1097, in load\n",
      "    return _load(\n",
      "           ^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1525, in _load\n",
      "    result = unpickler.load()\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1492, in persistent_load\n",
      "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1466, in load_tensor\n",
      "    wrap_storage=restore_location(storage, location),\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1392, in restore_location\n",
      "    return default_restore_location(storage, str(map_location))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 414, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 392, in _deserialize\n",
      "    return obj.to(device=device)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/storage.py\", line 187, in to\n",
      "    return _to(self, device, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 89, in _to\n",
      "    untyped_storage = torch.UntypedStorage(self.size(), device=device)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 106.12 MiB is free. Process 88261 has 14.63 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 130.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CPU times: user 1.31 s, sys: 281 ms, total: 1.59 s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test the concept detection\n",
    "!python test_concepts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWu2eyIYiEji"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Test the steerability\n",
    "!python train_classifier.py\n",
    "!python test_steerability.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVu3pb4diHSS"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Test the perplexity\n",
    "!python test_perplexity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRVpUNOEiIzi"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Visualize the top 10 tokens with the highest weight connect to a concept neuron\n",
    "!python test_weight.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7tCf-bciKGm"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Intervene the concept neurons and generate a sentence\n",
    "!python test_generation.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
